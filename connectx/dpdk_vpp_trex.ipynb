{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1e564b-d78f-4d04-9fc2-59d2f50b2798",
   "metadata": {},
   "source": [
    "# Smart NIC with DPDK, VPP and Pktgen-DPDK\n",
    "\n",
    "DPDK is the Data Plane Development Kit that consists of libraries to accelerate packet processing workloads running on a wide variety of CPU architectures. It is designed to run on x86, POWER, and ARM processors and licensed under the Open-Source BSD License.\n",
    "\n",
    "VPP is a high performance network stack that provides different dataplanes (Linux, RDMA and DPDK) and can be used as vSwitches, vRouters, Gateways, Firewalls and Load-Balancers.\n",
    "Pktgen-DPDK is a reference traffic generator, capable of generating 100Gbps using a single CPU core\n",
    "\n",
    "This notebook depicts how to attach Smart NICs to DPDK and send traffic to the DPDK connected NICs via TRex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6db1a8-273d-4d10-9997-b7fab997068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipaddress import ip_address, IPv4Address, IPv6Address, IPv4Network, IPv6Network\n",
    "import ipaddress\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395a86d5-a065-4074-85c2-5c05fab3d701",
   "metadata": {},
   "source": [
    "## Create the Experiment Slice\n",
    "\n",
    "The following creates two nodes with NIC_ConnectX_6/NIC_ConnectX_5 NICs connected to an isolated local Ethernet. \n",
    "- `vpp-node`: with one port connected to local L2 network. We will run VPP application here\n",
    "- `pktgen-node`: with one port connected to local L2 network. We wull run DPDK Packet Generator her \n",
    "\n",
    "In addition to local L2 network, each node is connected to FABNETv4 to be able to download the drivers from the Storage Node.\n",
    "\n",
    "<img src=\"./images/dpdk-pktgen-smart-nic.png\"><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d4a94-2251-493c-83e8-55bda78ed0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_name = 'MySlice-dpdk'\n",
    "site = fablib.get_random_site(filter_function=lambda x: x['nic_connectx_6_available'])\n",
    "print(f\"Site: {site}\")\n",
    "\n",
    "vpp_node_name = 'vpp-node'\n",
    "pktgen_node_name = 'pktgen-node'\n",
    "\n",
    "image_name = \"docker_ubuntu_22\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1689f4a2-a077-4a06-aa0c-802b9243fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Slice\n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "# Network\n",
    "net1 = slice.add_l2network(name='net1', subnet=IPv4Network(\"192.168.0.0/24\"))\n",
    "net2 = slice.add_l2network(name='net2', subnet=IPv4Network(\"192.168.1.0/24\"))\n",
    "\n",
    "# pktgen_node\n",
    "pktgen_node = slice.add_node(name=pktgen_node_name, site=site, cores=8, ram=16, disk=20, image=image_name)\n",
    "pktgen_node.add_fabnet()\n",
    "pktgen_node_iface1, pktgen_node_iface2 = pktgen_node.add_component(model='NIC_ConnectX_6', name='nic1').get_interfaces()\n",
    "\n",
    "# vpp_node\n",
    "vpp_node = slice.add_node(name=vpp_node_name, site=site, cores=8, ram=16, disk=20, image=image_name)\n",
    "vpp_node.add_fabnet()\n",
    "vpp_node_iface1, vpp_node_iface2 = vpp_node.add_component(model='NIC_ConnectX_6', name='nic1').get_interfaces()\n",
    "\n",
    "pktgen_node_iface1.set_mode('auto')\n",
    "pktgen_node_iface2.set_mode('auto')\n",
    "vpp_node_iface1.set_mode('auto')\n",
    "vpp_node_iface2.set_mode('auto')\n",
    "\n",
    "net1.add_interface(pktgen_node_iface1)\n",
    "net1.add_interface(vpp_node_iface1)\n",
    "\n",
    "net2.add_interface(pktgen_node_iface2)\n",
    "net2.add_interface(vpp_node_iface2)\n",
    "\n",
    "pktgen_node.add_post_boot_upload_directory('pktgen-dpdk','.')\n",
    "vpp_node.add_post_boot_upload_directory('vpp','.')\n",
    "\n",
    "for n in slice.get_nodes():\n",
    "    n.add_post_boot_upload_directory('node_tools','.')\n",
    "    n.add_post_boot_execute('chmod +x node_tools/*')\n",
    "    n.add_post_boot_execute('sudo node_tools/enable_docker.sh {{ _self_.image }} ')\n",
    "\n",
    "#Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee722dc9-5ed9-4850-b85e-07443015ef6c",
   "metadata": {},
   "source": [
    "## Verify connectivity between nodes on the local ethernet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31f4d1-f44d-4c7f-9a3a-7c5823202cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpp_node = slice.get_node(name=vpp_node_name)\n",
    "pktgen_node = slice.get_node(name=pktgen_node_name)\n",
    "\n",
    "\n",
    "pktgen_node_addr1 = pktgen_node.get_interface(network_name='net1').get_ip_addr()\n",
    "pktgen_node_addr2 = pktgen_node.get_interface(network_name='net2').get_ip_addr()\n",
    "\n",
    "\n",
    "stdout, stderr = vpp_node.execute(f'ping -c 5 {pktgen_node_addr1}')\n",
    "stdout, stderr = vpp_node.execute(f'ping -c 5 {pktgen_node_addr2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45d43-b255-46b3-9d5a-4f7df15f23d5",
   "metadata": {},
   "source": [
    "## Start and configure VPP container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c260a9-7249-42bb-ab61-271e51a9dbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose up -d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8730e-769e-4b2e-94a9-b86cda1182d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl create host-interface name {vpp_node_iface1.get_device_name()}')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set int ip address host-{vpp_node_iface1.get_device_name()} 192.168.0.2/24')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set interface state host-{vpp_node_iface1.get_device_name()} up')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl create host-interface name {vpp_node_iface2.get_device_name()}')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set int ip address host-{vpp_node_iface2.get_device_name()} 192.168.1.2/24')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set interface state host-{vpp_node_iface2.get_device_name()} up')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl show interface address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d056cd8-f92e-4a8e-898d-790236565862",
   "metadata": {},
   "source": [
    "## Configure MTU and firewall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2de691-dd66-4319-93c0-fd6a0788b8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pktgen_node = slice.get_node(name=pktgen_node_name)\n",
    "vpp_node = slice.get_node(name=vpp_node_name)\n",
    "\n",
    "pktgen_node_iface1 = pktgen_node.get_interface(network_name='net1')\n",
    "pktgen_node_iface2 = pktgen_node.get_interface(network_name='net2')\n",
    "\n",
    "vpp_node_iface1 = vpp_node.get_interface(network_name='net1')\n",
    "vpp_node_iface2 = vpp_node.get_interface(network_name='net2')\n",
    "stdout, stderr = vpp_node.execute(f'sudo ifconfig {vpp_node_iface1.get_device_name()} mtu 9000')\n",
    "stdout, stderr = vpp_node.execute(f'sudo ifconfig {vpp_node_iface2.get_device_name()} mtu 9000')\n",
    "stdout, stderr = vpp_node.execute(f'sudo nft insert rule ip filter FORWARD iifname {vpp_node_iface1.get_device_name()} oifname {vpp_node_iface2.get_device_name()} accept')\n",
    "stdout, stderr = vpp_node.execute(f'sudo nft insert rule ip filter FORWARD iifname {vpp_node_iface2.get_device_name()} oifname {vpp_node_iface1.get_device_name()} accept')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871b5e8-2134-41aa-9688-876bdc0f8c15",
   "metadata": {},
   "source": [
    "## Pktgen-DPDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f4f47-9bd0-4204-bd92-00348fb9c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = pktgen_node.execute(f'echo 2048 | sudo tee /sys/kernel/mm/hugepages/hugepages-2048kB/nr_hugepages')\n",
    "stdout, stderr = pktgen_node.execute(f'cd pktgen-dpdk; docker compose build -q')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e7d6b-d284-48d2-a5c7-ba6dc7fa8478",
   "metadata": {},
   "source": [
    "### Start Pktgen Application on pktgen-node\n",
    "\n",
    "Open a SSH console for `pktgen-node` and start `pktgen` using the commands generated by the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265c46c-2647-4270-90f8-ad20e9d1d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Open a SSH console for {pktgen_node.get_name()} using the command: {pktgen_node.get_ssh_command()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e2f13-09bd-4db6-9539-7957b95cc80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start DPDK PKTGEN using the command: \")\n",
    "if \"rocky\" in pktgen_node.get_image():\n",
    "    print(\"export PKG_CONFIG_PATH=/usr/local/lib64/pkgconfig\")\n",
    "    print(\"cd Pktgen-DPDK\")\n",
    "else:\n",
    "    print(\"cd pktgen-dpdk\")\n",
    "print(f\"docker compose run --rm pktgen-dpdk pktgen -a {pktgen_node_iface1.get_component().get_pci_addr()[0]} -a {pktgen_node_iface2.get_component().get_pci_addr()[1]}  -l 0-4 -n 3 -- -m \\\"[1:3].0, [2:4].1\\\" -j\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5b027d-7ea6-481d-b731-dddd08ce6b0b",
   "metadata": {},
   "source": [
    "After Pktgen is brought up, set up Pktgen and start traffic by running the commands generated by the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8cc4d-5481-475a-b201-de3750819db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"set 0 proto udp\")\n",
    "print(\"set 0 size 9000\")\n",
    "print(f\"set 0 src ip {pktgen_node_iface1.get_ip_addr()}\")\n",
    "print(f\"set 0 dst ip {pktgen_node_iface2.get_ip_addr()}\")\n",
    "print(f\"set 0 dst mac {vpp_node_iface1.get_mac().lower()}\")\n",
    "print(\"start 0\")\n",
    "print(\"enable 1 process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f72d9-a02b-4de0-baf8-28d34a07dad7",
   "metadata": {},
   "source": [
    "Pktgen-DPDK will start updating the statistics on the top of the page, where you can spot the transmitted rate (TX) on port 0 and the receive rate on port 1 (RX) on line 6 (MBits/s Rx/Tx). In the following example itâ€™s transmitting 98.4 Gbps (100753 Mbps / 1024) and receiving only 17 Gbps (17468 Mbps / 1024) using the Linux datapath."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d883c0-141e-44f0-be31-597beced1fe1",
   "metadata": {},
   "source": [
    "Keep Pktgen running since it will be used to check the throughput of the SmartNIC using offloads using RDMA and DPDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464fc6c-ab78-4a63-89f2-d00030b2d21a",
   "metadata": {},
   "source": [
    "## Setting up the VPP SmartNIC with RDMA offload\n",
    "VPP provides a RDMA device driver[5], which uses RDMA APIs available on Nvidia ConnectX SmartNICS to offload Ethernet packets. To use it, the VPP container will be restarted to clean up the configurations and RDMA interfaces will be configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e83c09-bc12-4497-8981-2833ee65d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose restart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d20d52-b897-460b-8b9a-1cf8c58ec247",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl create interface rdma host-if {vpp_node_iface1.get_device_name()} name rdma-0')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set int ip address rdma-0 {vpp_node_iface1.get_ip_addr()}/24')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set interface state rdma-0 up')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl create interface rdma host-if {vpp_node_iface2.get_device_name()} name rdma-1')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set int ip address rdma-1 {vpp_node_iface2.get_ip_addr()}/24')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set interface state rdma-1 up')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl show interface address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4529d164-b34b-4618-b2cb-16b9895d59ae",
   "metadata": {},
   "source": [
    "Now go back to Pktgen-DPDK and verify that the receiving rate has increased by a factor of approximately 2.6 times, to 44 Gbps (45348 Mbps / 1024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745acf07-4352-4d59-bcfe-0e870fcb8a56",
   "metadata": {},
   "source": [
    "## Setting up the VPP SmartNIC with DPDK offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb02baf6-fcf3-4dcf-aa23-e43abe9da346",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = vpp_node.execute(f'echo 2048 | sudo tee /proc/sys/vm/nr_hugepages')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose down')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose -f compose.yaml up -d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa11b7-79a6-447a-a763-2c270d97db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set int ip address HundredGigabitEthernet8/0/0 {vpp_node_iface1.get_ip_addr()}/24')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set interface state HundredGigabitEthernet8/0/0 up')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set int ip address HundredGigabitEthernet9/0/0 {vpp_node_iface2.get_ip_addr()}/24')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl set interface state HundredGigabitEthernet9/0/0 up')\n",
    "stdout, stderr = vpp_node.execute(f'cd vpp; docker compose exec vpp vppctl show interface address')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d9c18-e0f7-441f-8ef7-097fb708746c",
   "metadata": {},
   "source": [
    "Finally, go back to Pktgen-DPDK and verify that the receiving rate has increased again by a factor of approximately 5.8 times compared to the original test, to 99.2 Gbps (101543 Mbps / 1024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb95eb0-70ae-487b-91d7-3740bf23b821",
   "metadata": {},
   "source": [
    "## Delete the Slice\n",
    "\n",
    "Please delete your slice when you are done with your experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5688713-e450-4354-bf9a-57382e2e2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "slice.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1b597b-6ae2-4194-9986-a0c194e94b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
